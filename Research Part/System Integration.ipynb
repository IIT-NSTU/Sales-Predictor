{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine, text\n",
    "from sqlalchemy.orm import Session\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import date, datetime, timedelta\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.metrics import classification_report, mean_absolute_error\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the Laravel MySQL database\n",
    "user = 'root'\n",
    "password = ''\n",
    "host = 'localhost'\n",
    "database = 'sales_predictor'\n",
    "\n",
    "# Create a SQLAlchemy engine\n",
    "engine = create_engine(f'mysql+pymysql://{user}:{password}@{host}/{database}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = pd.read_sql('SELECT * from users', engine)\n",
    "\n",
    "for index in users.index:\n",
    "    user_id = users.loc[index]['id']\n",
    "    invoice_products = pd.read_sql(\"SELECT i.date AS date, ip.product_id AS product_id, ip.quantity AS unit FROM invoice_products ip JOIN invoices i ON ip.invoice_id = i.id where ip.user_id='\"+ str(user_id) + \"'\", engine)\n",
    "    \n",
    "    if len(invoice_products) > 0:\n",
    "        invoice_products['date'] = pd.to_datetime(invoice_products['date'], format = '%Y-%m-%d %I:%M:%S %p', errors = 'coerce').dt.date\n",
    "        \n",
    "        # Create a pivot table with 'date' as rows and 'product_id' as columns\n",
    "        pivot_table = invoice_products.pivot_table(index = 'date', columns = 'product_id', values = 'unit', aggfunc = 'sum', fill_value = 0)\n",
    "\n",
    "        # Reindex to include all dates from the first to the last date in the data\n",
    "        date_range = pd.date_range(start = invoice_products['date'].min(), end = invoice_products['date'].max())\n",
    "        pivot_table = pivot_table.reindex(date_range, fill_value=0)\n",
    "\n",
    "        # Reset index to make 'date' a column again\n",
    "        pivot_table.index.name = 'date'\n",
    "        pivot_table = pivot_table.reset_index()\n",
    "\n",
    "        pivot_table['day_of_year'] = pivot_table['date'].dt.dayofyear\n",
    "        pivot_table['month'] = pivot_table['date'].dt.month\n",
    "        pivot_table['day_of_week'] = pivot_table['date'].dt.dayofweek\n",
    "        pivot_table['day_of_month'] = pivot_table['date'].dt.day\n",
    "        pivot_table = pivot_table.drop(columns='date')\n",
    "        \n",
    "        classification_data = pivot_table[['day_of_year', 'month', 'day_of_week', 'day_of_month']].copy()\n",
    "\n",
    "        # Ensure all product columns are numeric\n",
    "        pivot_table = pivot_table.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "        columns_to_concat = []\n",
    "\n",
    "        products = pivot_table.columns.to_list()[:-5]\n",
    "\n",
    "        for product in products:\n",
    "            # Defining conditions here\n",
    "            conditions = [\n",
    "                pivot_table[product] > 2,\n",
    "                pivot_table[product] == 2,\n",
    "                pivot_table[product] == 1,\n",
    "                pivot_table[product] == 0\n",
    "            ]\n",
    "\n",
    "            # Defining the corresponding outputs for each condition\n",
    "            choices = [3, 2, 1, 0]\n",
    "\n",
    "            # Apply np.select and store the result in a separate DataFrame\n",
    "            classification_column = pd.DataFrame({\n",
    "                product: np.select(conditions, choices, default = 0)\n",
    "            })\n",
    "\n",
    "            # Append this column to the list of columns to concatenate\n",
    "            columns_to_concat.append(classification_column)\n",
    "\n",
    "        # Step 3: Concatenate all columns at once\n",
    "        classification_data = pd.concat([classification_data] + columns_to_concat, axis=1)\n",
    "\n",
    "        # Getting the the product column names\n",
    "        product_columns = classification_data.columns.difference(['day_of_year', 'month', 'day_of_week', 'day_of_month'])\n",
    "\n",
    "        pids = pd.DataFrame(product_columns, columns=['id'])\n",
    "        \n",
    "        # Setting the dependent and independent variable\n",
    "        X = classification_data[['day_of_year', 'month', 'day_of_week']]\n",
    "        y = classification_data[product_columns]\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "        clf = MultiOutputClassifier(RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        # Predict the classification output for the training data\n",
    "        y_pred = clf.predict(X_train)\n",
    "\n",
    "        # Create a dictionary to store regression models for each product\n",
    "        regression_models = {}\n",
    "\n",
    "        # Loop through each product\n",
    "        for position, product in enumerate(product_columns):\n",
    "            \n",
    "            # Filter the rows where the predicted label is 3 for the current product\n",
    "            mask = y_pred[:, position] == 3\n",
    "            \n",
    "            # Select the relevant rows from X_train based on the mask\n",
    "            X_train_reg = X_train[mask].copy()\n",
    "            \n",
    "            if (len(X_train_reg) > 0):\n",
    "\n",
    "                # Create the target series (y_train_reg) for regression, based on the original 'data' DataFrame\n",
    "                y_train_reg = pivot_table.loc[X_train_reg.index, product]\n",
    "\n",
    "                # Initialize the SGDRegressor with a small learning rate\n",
    "                reg = SGDRegressor(max_iter=2000, tol=1e-3, random_state=42)\n",
    "\n",
    "                # Scaling the data for regression\n",
    "                scaler = StandardScaler()\n",
    "                X_train_reg_scaled = scaler.fit_transform(X_train_reg) \n",
    "                    \n",
    "                # Train the regression model with SGDRegressor\n",
    "                reg.fit(X_train_reg_scaled, y_train_reg)\n",
    "                \n",
    "                # Store the regression model\n",
    "                regression_models[product] = reg\n",
    "        \n",
    "        # Saving model to pickle file\n",
    "        with open(\"model/\" + str(user_id) + \"_classifier.pkl\", \"wb\") as file: \n",
    "            pickle.dump(clf, file)\n",
    "\n",
    "        # Save the models in one pickle file\n",
    "        with open(\"model/\" + str(user_id) + \"_regressor.pkl\", \"wb\") as f:\n",
    "            pickle.dump(regression_models, f)\n",
    "\n",
    "        pids.to_csv(\"model/\" + str(user_id) + \"_pids.csv\", index=False)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = datetime(2022, 4, 1)\n",
    "dates = [start_date + timedelta(days=i) for i in range(365 * 3)]\n",
    "\n",
    "df = pd.DataFrame({'Date': dates})\n",
    "\n",
    "df['day_of_year'] = df['Date'].dt.dayofyear\n",
    "df['month'] = df['Date'].dt.month\n",
    "df['day_of_week'] = df['Date'].dt.dayofweek  # Monday=0, Sunday=6\n",
    "df['day_of_month'] = df['Date'].dt.day\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(df[['day_of_year', 'month', 'day_of_week', 'day_of_month']])\n",
    "\n",
    "df_scaled = pd.DataFrame(scaled_features, columns=['day_of_year_scaled', 'month_scaled', 'day_of_week_scaled', 'day_of_month_scaled'])\n",
    "df = pd.concat([df, df_scaled], axis=1)\n",
    "\n",
    "users = pd.read_sql('SELECT * from users', engine)\n",
    "\n",
    "for index in users.index:\n",
    "    user_id = users.loc[index]['id']\n",
    "    \n",
    "    classifier_path = \"model/\" + str(user_id) + \"_classifier.pkl\"\n",
    "    regressor_path = \"model/\" + str(user_id) + \"_regressor.pkl\"\n",
    "    \n",
    "    if os.path.isfile(classifier_path):\n",
    "        # Opening saved model\n",
    "        with open(classifier_path, \"rb\") as file:\n",
    "            classifier = pickle.load(file)\n",
    "\n",
    "        with open(regressor_path, \"rb\") as f:\n",
    "            regressor = pickle.load(f)    \n",
    "\n",
    "        today = date.today()\n",
    "        prediction_dates = [today + timedelta(days = i) for i in range(30)]\n",
    "\n",
    "        product_data = pd.read_csv(\"model/\" + str(user_id) + \"_pids.csv\")\n",
    "\n",
    "        sql = \"INSERT INTO `predictions` (`id`, `date`, `product_id`, `unit`, `user_id`, `created_at`, `updated_at`) VALUES \"\n",
    "\n",
    "        for date in prediction_dates:\n",
    "            result = classifier.predict(pd.DataFrame({'day_of_year': date.timetuple().tm_yday, 'month':date.month, 'day_of_week':date.weekday()}, index = [0]))\n",
    "            i = 0\n",
    "            for value in result[0]:\n",
    "                if not value == 0:\n",
    "                    unit = value\n",
    "                    if value == 3 and product_data['id'][i] in regressor:\n",
    "                        row = df[(df['day_of_year'] == date.timetuple().tm_yday) \n",
    "                                 & (df['month'] == date.month)\n",
    "                                 & (df['day_of_week'] == date.weekday())\n",
    "                                 & (df['day_of_month'] == date.day)]\n",
    "                        row = row.reset_index()\n",
    "                        test_data = [[row.loc[0]['day_of_year_scaled'], row.loc[0]['month_scaled'], row.loc[0]['day_of_week_scaled']]]\n",
    "                        result = regressor[product_data['id'][i]].predict(test_data)\n",
    "                        unit = round(result[0])\n",
    "\n",
    "                    sql += \"(NULL, '\" + str(date) + \"', '\" + str(product_data['id'][i]) + \"', '\" + str(unit) + \"', '\" + str(user_id) + \"', CURRENT_TIMESTAMP, CURRENT_TIMESTAMP),\"\n",
    "                i += 1\n",
    "\n",
    "        with Session(engine) as session:\n",
    "            session.execute(text(\"DELETE from `predictions` WHERE user_id = \" + str(user_id)))\n",
    "            session.execute(text(sql[:-1]))\n",
    "            session.commit() \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Opening saved model\n",
    "# with open(\"model/classifier.pkl\", \"rb\") as file:\n",
    "#     classifier = pickle.load(file)\n",
    "\n",
    "# product_data = pd.read_csv(\"dataset/Project Dataset/product.csv\")\n",
    "\n",
    "# product_data = product_data.sort_values(\"product\").reset_index().drop(columns=['index'])\n",
    "\n",
    "# today = date.today()\n",
    "# prediction_dates = [today + timedelta(days = i) for i in range(30)]\n",
    "\n",
    "# sql = \"INSERT INTO `predictions` (`id`, `date`, `product_id`, `unit`, `user_id`, `created_at`, `updated_at`) VALUES \"\n",
    "\n",
    "# for date in prediction_dates:\n",
    "#     result = classifier.predict(pd.DataFrame({'day_of_year': date.timetuple().tm_yday, 'month':date.month, 'day_of_week':date.weekday()}, index = [0]))\n",
    "#     i = 0\n",
    "#     for value in result[0]:\n",
    "#         if not value == 0:\n",
    "#             sql += \"(NULL, '\" + str(date) + \"', '\" + str(product_data['id'][i]) + \"', '\" + str(value) + \"', '5', CURRENT_TIMESTAMP, CURRENT_TIMESTAMP),\"\n",
    "#         i += 1\n",
    "# print(sql)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
